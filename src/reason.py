import torch
import cv2
import numpy as np
from ultralytics import YOLO
from collections import defaultdict
import time
from PyQt5.QtCore import QThread, pyqtSignal
import queue

class RGBBallTracker:
    def __init__(self, model_path, confidence_threshold=0.55, device='auto'):
        """
        åˆå§‹åŒ–RGBçƒè¿½è¸ªå™¨
        
        Args:
            model_path: YOLOæ¨¡å‹æ–‡ä»¶è·¯å¾„
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            device: è®¾å¤‡é€‰æ‹© ('auto', 'cpu', 'cuda:0', 'cuda:1', etc.)
        """
        # è‡ªåŠ¨é€‰æ‹©æœ€ä½³è®¾å¤‡
        if device == 'auto':
            if torch.cuda.is_available():
                device = 'cuda:0'
                print(f"âœ“ è‡ªåŠ¨é€‰æ‹©GPU: {torch.cuda.get_device_name(0)}")
                print(f"âœ“ GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
            else:
                device = 'cpu'
                print("âš  GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
        else:
            if device.startswith('cuda') and not torch.cuda.is_available():
                print("âš  æŒ‡å®šGPUä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU")
                device = 'cpu'
            elif device.startswith('cuda'):
                gpu_id = int(device.split(':')[1]) if ':' in device else 0
                if gpu_id < torch.cuda.device_count():
                    print(f"âœ“ ä½¿ç”¨æŒ‡å®šGPU: {torch.cuda.get_device_name(gpu_id)}")
                else:
                    print(f"âš  GPU {gpu_id} ä¸å­˜åœ¨ï¼Œä½¿ç”¨GPU 0")
                    device = 'cuda:0'
        
        self.device = device
        self.confidence_threshold = confidence_threshold
        
        # åŠ è½½æ¨¡å‹
        print(f"ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹...")
        self.model = YOLO(model_path)
        
        # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        if device != 'cpu':
            print(f"ğŸ”„ å°†æ¨¡å‹ç§»åŠ¨åˆ° {device}...")
            self.model.to(device)
        
        print(f"âœ“ æ¨¡å‹å·²åŠ è½½åˆ° {device}")
        
        # GPUä¼˜åŒ–è®¾ç½®
        if device.startswith('cuda'):
            self._setup_gpu_optimization()
        
        # å®šä¹‰é¢œè‰²æ˜ å°„ (BGRæ ¼å¼)
        self.colors = {
            'red': (0, 0, 255),
            'green': (0, 255, 0),
            'blue': (255, 0, 0)
        }
        
        # ç±»åˆ«åç§°æ˜ å°„ï¼ˆæ ¹æ®ä½ çš„æ¨¡å‹è®­ç»ƒæ—¶çš„ç±»åˆ«é¡ºåºè°ƒæ•´ï¼‰
        self.class_names = {
            0: 'red_ball',
            1: 'green_ball', 
            2: 'blue_ball'
        }
        
        # è¿½è¸ªå†å²è®°å½•
        self.tracking_history = defaultdict(list)
        self.frame_count = 0
        
        # æ€§èƒ½ç›‘æ§
        self.inference_times = []
        self.total_inference_time = 0
        
        # GPUé¢„çƒ­
        if device.startswith('cuda'):
            self._warmup_model()
    
    def _setup_gpu_optimization(self):
        """è®¾ç½®GPUä¼˜åŒ–"""
        try:
            # å¯ç”¨CUDNNåŸºå‡†æ¨¡å¼ï¼ˆå›ºå®šè¾“å…¥å°ºå¯¸æ—¶æœ‰æ•ˆï¼‰
            torch.backends.cudnn.benchmark = True
            print("âœ“ CUDNNåŸºå‡†æ¨¡å¼å·²å¯ç”¨")
        except Exception as e:
            print(f"âš  GPUä¼˜åŒ–è®¾ç½®å¤±è´¥: {e}")
    
    def _warmup_model(self, warmup_frames=5):
        """GPUæ¨¡å‹é¢„çƒ­"""
        print("ğŸ”¥ GPUæ¨¡å‹é¢„çƒ­ä¸­...")
        dummy_frame = np.random.randint(0, 255, (640, 480, 3), dtype=np.uint8)
        
        for i in range(warmup_frames):
            with torch.no_grad():
                _ = self.model(dummy_frame, verbose=False)
            if torch.cuda.is_available():
                torch.cuda.synchronize()
        
        print("âœ“ GPUé¢„çƒ­å®Œæˆ")
        
    def process_frame(self, frame, isPrintInfo=True):
        """
        å¤„ç†å•å¸§å›¾åƒ
        
        Args:
            frame: è¾“å…¥å›¾åƒå¸§
            isPrintInfo: æ˜¯å¦æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            
        Returns:
            processed_frame: å¤„ç†åçš„å›¾åƒå¸§
            detections: æ£€æµ‹ç»“æœ
        """


        # è®°å½•æ¨ç†å¼€å§‹æ—¶é—´
        inference_start = time.perf_counter()
        
        # è¿è¡ŒYOLOæ¨ç† - GPUä¼˜åŒ–æ¨ç†
        with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—èŠ‚çœæ˜¾å­˜
            if self.device.startswith('cuda'):
                # GPUæ¨ç†æ—¶ä½¿ç”¨æ··åˆç²¾åº¦åŠ é€Ÿ
                with torch.cuda.amp.autocast():
                    results = self.model(frame, conf=self.confidence_threshold, verbose=False)
                # ç¡®ä¿GPUæ“ä½œå®Œæˆ
                torch.cuda.synchronize()
            else:
                # CPUæ¨ç†
                results = self.model(frame, conf=self.confidence_threshold, verbose=False)
        
        # è®°å½•æ¨ç†æ—¶é—´
        inference_end = time.perf_counter()
        inference_time = inference_end - inference_start
        self.inference_times.append(inference_time)
        self.total_inference_time += inference_time
        
        # å¤åˆ¶å¸§ç”¨äºç»˜åˆ¶
        processed_frame = frame.copy()
        detections = []
        
        # å¤„ç†æ£€æµ‹ç»“æœ
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    # è·å–è¾¹ç•Œæ¡†åæ ‡
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    confidence = float(box.conf[0])
                    class_id = int(box.cls[0])
                    # è·å–ç±»åˆ«åç§°
                    class_name = self.class_names.get(class_id, f'class_{class_id}')
                    # è®¡ç®—ä¸­å¿ƒç‚¹
                    center_x = (x1 + x2) // 2
                    center_y = (y1 + y2) // 2
                    # è®°å½•æ£€æµ‹ç»“æœ
                    detection = {
                        'bbox': (x1, y1, x2, y2),
                        'center': (center_x, center_y),
                        'confidence': confidence,
                        'class_name': class_name,
                        'class_id': class_id
                    }
                    detections.append(detection)

        # åªä¿ç•™æ¯ç§çƒç±»å‹ç½®ä¿¡åº¦æœ€é«˜çš„ä¸€ä¸ª
        best_detections = {}
        for det in detections:
            cname = det['class_name']
            if cname not in best_detections or det['confidence'] > best_detections[cname]['confidence']:
                best_detections[cname] = det
        detections = list(best_detections.values())

        # ç»˜åˆ¶å’Œè¿½è¸ªä»…å¯¹ç­›é€‰åçš„æ£€æµ‹è¿›è¡Œ
        for detection in detections:
            x1, y1, x2, y2 = detection['bbox']
            center_x, center_y = detection['center']
            confidence = detection['confidence']
            class_name = detection['class_name']
            color = self.get_color_for_class(class_name)
            # æ›´æ–°è¿½è¸ªå†å²
            self.tracking_history[class_name].append((center_x, center_y))
            if len(self.tracking_history[class_name]) > 50:
                self.tracking_history[class_name].pop(0)
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(processed_frame, (x1, y1), (x2, y2), color, 2)
            # ç»˜åˆ¶æ ‡ç­¾
            label = f'{class_name}: {confidence:.2f}'
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            cv2.rectangle(processed_frame, 
                        (x1, y1 - label_size[1] - 10), 
                        (x1 + label_size[0], y1), 
                        color, -1)
            cv2.putText(processed_frame, label, 
                      (x1, y1 - 5), 
                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
            cv2.circle(processed_frame, (center_x, center_y), 5, color, -1)

        # ç»˜åˆ¶è¿½è¸ªè½¨è¿¹
        self.draw_tracking_trails(processed_frame)

        # ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯
        if isPrintInfo:
            self.draw_statistics(processed_frame, detections, inference_time)

        return processed_frame, detections
    
    def get_color_for_class(self, class_name):
        """æ ¹æ®ç±»åˆ«åç§°è·å–é¢œè‰²"""
        if 'red' in class_name.lower():
            return self.colors['red']
        elif 'green' in class_name.lower():
            return self.colors['green']
        elif 'blue' in class_name.lower():
            return self.colors['blue']
        else:
            return (128, 128, 128)  # ç°è‰²ä½œä¸ºé»˜è®¤é¢œè‰²
    
    def draw_tracking_trails(self, frame):
        """ç»˜åˆ¶è¿½è¸ªè½¨è¿¹"""
        for class_name, points in self.tracking_history.items():
            if len(points) > 1:
                color = self.get_color_for_class(class_name)
                # ç»˜åˆ¶è½¨è¿¹çº¿
                for i in range(1, len(points)):
                    cv2.line(frame, points[i-1], points[i], color, 1)
    
    def draw_statistics(self, frame, detections, inference_time):
        """ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯"""
        h, w = frame.shape[:2]
        
        # ç»Ÿè®¡å„ç±»çƒçš„æ•°é‡
        stats = defaultdict(int)
        for det in detections:
            stats[det['class_name']] += 1
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        avg_inference_time = np.mean(self.inference_times[-30:]) if self.inference_times else 0
        theoretical_fps = 1 / avg_inference_time if avg_inference_time > 0 else 0
        
        # ç»˜åˆ¶èƒŒæ™¯ - æ‰©å¤§ä»¥æ˜¾ç¤ºæ›´å¤šä¿¡æ¯
        info_height = 180 if self.device.startswith('cuda') else 140
        cv2.rectangle(frame, (10, 10), (350, info_height), (0, 0, 0), -1)
        cv2.rectangle(frame, (10, 10), (350, info_height), (255, 255, 255), 2)
        
        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        y_pos = 30
        cv2.putText(frame, f'Frame: {self.frame_count}', 
                   (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        y_pos += 20
        cv2.putText(frame, f'Device: {self.device}', 
                   (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        # æ˜¾ç¤ºæ€§èƒ½ä¿¡æ¯
        y_pos += 20
        cv2.putText(frame, f'Inference: {inference_time*1000:.1f}ms', 
                   (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
        
        y_pos += 20
        cv2.putText(frame, f'Avg FPS: {theoretical_fps:.1f}', 
                   (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
        
        # æ˜¾ç¤ºGPUä¿¡æ¯
        if self.device.startswith('cuda') and torch.cuda.is_available():
            y_pos += 20
            memory_used = torch.cuda.memory_allocated() / 1024**3
            cv2.putText(frame, f'GPU Mem: {memory_used:.2f}GB', 
                       (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)
        
        # æ˜¾ç¤ºæ£€æµ‹ç»Ÿè®¡
        y_pos += 25
        for class_name in ['red_ball', 'green_ball', 'blue_ball']:
            count = stats.get(class_name, 0)
            color = self.get_color_for_class(class_name)
            cv2.putText(frame, f'{class_name}: {count}', 
                       (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            y_pos += 20
        
        self.frame_count += 1
    
    def get_performance_stats(self):
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        if not self.inference_times:
            return None
        
        return {
            'avg_inference_ms': np.mean(self.inference_times) * 1000,
            'min_inference_ms': np.min(self.inference_times) * 1000,
            'max_inference_ms': np.max(self.inference_times) * 1000,
            'theoretical_fps': 1 / np.mean(self.inference_times),
            'total_frames': len(self.inference_times)
        }
    
# ç»§æ‰¿è‡ª QThreadï¼Œç”¨äºå¤„ç† YOLO æ¨ç†

class YOLOThread(QThread):
    # å®šä¹‰ä¿¡å·ï¼Œç”¨äºå‘ä¸»çº¿ç¨‹å‘é€æ¨ç†ç»“æœ
    inference_result = pyqtSignal(np.ndarray, list)  # (processed_frame, detections)
    inference_stats = pyqtSignal(dict)  # æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
    error_occurred = pyqtSignal(str)  # é”™è¯¯ä¿¡æ¯
    
    def __init__(self, path_model, queue_frame, parent=None):
        super().__init__(parent)
        
        
        self.rgb_tracker = RGBBallTracker(path_model, confidence_threshold=0.55, device='auto')
        self.queue_frame = queue_frame
        self.running = False
        
        # æ¨ç†æ§åˆ¶å‚æ•°
        self.max_queue_size = 5  # é˜Ÿåˆ—æœ€å¤§å¤§å°ï¼Œé˜²æ­¢ç§¯å‹
        self.inference_interval = 0.033  # æ¨ç†é—´éš”ï¼Œçº¦30 FPS
        self.skip_frames = False  # æ˜¯å¦è·³å¸§å¤„ç†
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.processed_frames = 0
        self.skipped_frames = 0
        self.last_stats_time = time.time()
        
    def run(self):
        """çº¿ç¨‹ä¸»å¾ªç¯"""
        print("ğŸš€ YOLOæ¨ç†çº¿ç¨‹å¯åŠ¨")
        self.running = True
        last_inference_time = time.time()
        
        while self.running:
            # print('i am reasoning')
            try:
               
                # æ§åˆ¶æ¨ç†é¢‘ç‡
                current_time = time.time()
                if current_time - last_inference_time < self.inference_interval:
                    time.sleep(0.01)
                    continue
                
                # è·å–å¸§è¿›è¡Œæ¨ç†
                frame = self._get_latest_frame()
                if frame is None:
                    time.sleep(0.01)
                    continue
                
                # æ‰§è¡Œæ¨ç†
                processed_frame, detections = self.rgb_tracker.process_frame(
                    frame, isPrintInfo=True
                )
                
                # å‘é€æ¨ç†ç»“æœåˆ°ä¸»çº¿ç¨‹
                self.inference_result.emit(processed_frame, detections)
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self.processed_frames += 1
                last_inference_time = current_time
                
                # å®šæœŸå‘é€æ€§èƒ½ç»Ÿè®¡
                if current_time - self.last_stats_time > 1.0:  # æ¯ç§’æ›´æ–°ä¸€æ¬¡
                    self._emit_stats()
                    self.last_stats_time = current_time
                
            except queue.Empty:
                time.sleep(0.01)
                continue
            except Exception as e:
                error_msg = f"æ¨ç†çº¿ç¨‹é”™è¯¯: {str(e)}"
                print(f"âŒ {error_msg}")
                self.error_occurred.emit(error_msg)
                self.running = False
                break
        
        print("ğŸ›‘ YOLOæ¨ç†çº¿ç¨‹ç»“æŸ")
    
    def _get_latest_frame(self):
        """
        ä»é˜Ÿåˆ—è·å–æœ€æ–°å¸§ï¼Œå¯é€‰æ‹©æ€§è·³å¸§
        
        Returns:
            frame: è·å–åˆ°çš„å¸§ï¼Œå¦‚æœé˜Ÿåˆ—ä¸ºç©ºè¿”å›None
        """
        frame = None
        frames_in_queue = 0
        
        # try:
        #     # å¦‚æœå¯ç”¨è·³å¸§ï¼Œè·å–é˜Ÿåˆ—ä¸­æœ€æ–°çš„å¸§
        #     if self.skip_frames:
        #         # æ¸…ç©ºæ—§å¸§ï¼Œåªä¿ç•™æœ€æ–°çš„
        #         while not self.frame_queue.empty():
        #             frame = self.frame_queue.get_nowait()
        #             frames_in_queue += 1
                
        #         # ç»Ÿè®¡è·³è¿‡çš„å¸§æ•°
        #         if frames_in_queue > 1:
        #             self.skipped_frames += frames_in_queue - 1
                    
        #     else:
        #         # ä¸è·³å¸§ï¼ŒæŒ‰é¡ºåºå¤„ç†
        #         if not self.frame_queue.empty():
        #             frame = self.frame_queue.get_nowait()
        #             frames_in_queue = 1
            
        #     # å¦‚æœé˜Ÿåˆ—ç§¯å‹è¿‡å¤šï¼Œè‡ªåŠ¨å¯ç”¨è·³å¸§
        #     if self.frame_queue.qsize() > self.max_queue_size:
        #         self.skip_frames = True
        #         print(f"âš ï¸ é˜Ÿåˆ—ç§¯å‹({self.frame_queue.qsize()})ï¼Œå¯ç”¨è·³å¸§æ¨¡å¼")
        #     elif self.frame_queue.qsize() < 2:
        #         self.skip_frames = False
                
        # except queue.Empty:
        #     pass
        # except Exception as e:
        #     print(f"è·å–å¸§æ—¶å‡ºé”™: {e}")
        frame = self.queue_frame.get()
        
        return frame
    
    def _emit_stats(self):
        """å‘é€ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # è·å–RGBè¿½è¸ªå™¨çš„æ€§èƒ½ç»Ÿè®¡
            tracker_stats = self.rgb_tracker.get_performance_stats()
            
            # ç»¼åˆç»Ÿè®¡ä¿¡æ¯
            stats = {
                'processed_frames': self.processed_frames,
                'skipped_frames': self.skipped_frames,
                'queue_size': self.queue_frame.qsize(),
                'skip_mode': self.skip_frames,
                'tracker_stats': tracker_stats
            }
            
            self.inference_stats.emit(stats)
            
        except Exception as e:
            print(f"å‘é€ç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºé”™: {e}")
    
    def start_inference(self):
        """å¯åŠ¨æ¨ç†"""
        if not self.running:
            print("â–¶ï¸ å¯åŠ¨YOLOæ¨ç†çº¿ç¨‹")
            self.start()
        else:
            print("â–¶ï¸ YOLOå·²åœ¨æ¨ç†")
    

    
    def stop_inference(self):
        """åœæ­¢æ¨ç†çº¿ç¨‹"""
        print("â¹ï¸ åœæ­¢YOLOæ¨ç†çº¿ç¨‹")
        self.running = False
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸï¼Œä½†è®¾ç½®è¶…æ—¶
        if self.isRunning():
            self.wait(1000)  # æœ€å¤šç­‰å¾…3ç§’
            if self.isRunning():
                print("âš ï¸ æ¨ç†çº¿ç¨‹æœªèƒ½æ­£å¸¸ç»“æŸï¼Œå¼ºåˆ¶ç»ˆæ­¢")
                self.terminate()
    
    def set_inference_params(self, fps_limit=30, enable_skip_frames=None, max_queue_size=None):
        """
        è®¾ç½®æ¨ç†å‚æ•°
        
        Args:
            fps_limit: FPSé™åˆ¶
            enable_skip_frames: æ˜¯å¦å¯ç”¨è·³å¸§
            max_queue_size: æœ€å¤§é˜Ÿåˆ—å¤§å°
        """
        self.inference_interval = 1.0 / fps_limit if fps_limit > 0 else 0.033
        
        if enable_skip_frames is not None:
            self.skip_frames = enable_skip_frames
            
        if max_queue_size is not None:
            self.max_queue_size = max_queue_size
        
        print(f"ğŸ”§ æ¨ç†å‚æ•°å·²æ›´æ–°: FPSé™åˆ¶={fps_limit}, è·³å¸§={self.skip_frames}, æœ€å¤§é˜Ÿåˆ—={self.max_queue_size}")
    
    def clear_queue(self):
        """æ¸…ç©ºå¸§é˜Ÿåˆ—"""
        try:
            cleared_count = 0
            while not self.queue_frame.empty():
                self.queue_frame.get_nowait()
                cleared_count += 1
            
            if cleared_count > 0:
                print(f"ğŸ—‘ï¸ æ¸…ç©ºäº† {cleared_count} å¸§")
                
        except Exception as e:
            print(f"æ¸…ç©ºé˜Ÿåˆ—æ—¶å‡ºé”™: {e}")
    
    def get_status(self):
        """è·å–çº¿ç¨‹çŠ¶æ€"""
        return {
            'running': self.running,
            'processed_frames': self.processed_frames,
            'skipped_frames': self.skipped_frames,
            'queue_size': self.queue_frame.qsize(),
            'skip_mode': self.skip_frames
        }

def merge_3d_tracks_frame(det0, det1):
	# det0, det1: list of detection dicts
	# è¿”å›: {class_name: (x0, y0, x1)}
	d3 = {}
	for cname in ["red_ball", "green_ball", "blue_ball"]:
		c0 = next((d for d in det0 if d['class_name']==cname), None)
		c1 = next((d for d in det1 if d['class_name']==cname), None)
		if c0 and c1:
			d3[cname] = (c0['center'][0], c0['center'][1], c1['center'][0])
	return d3

